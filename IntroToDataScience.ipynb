{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IntroToDataScience.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPR6CqNJtGwSmAwAwl3b6ag",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TobiasM95/IntroDataScience/blob/main/IntroToDataScience.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Prologue\n",
        "\n",
        "##What is Data Science\n",
        "\n",
        "###- Working with data\n",
        "###- Where does data come from\n",
        "###- Quantification of events\n",
        "###- Where can you find data science\n",
        "###- What forms of data science exist\n",
        "\n",
        "##Components of this notebook\n",
        "\n",
        "###- Introduction to the technology used here\n",
        "###- Load and transforming of data\n",
        "###- Visualizing of data\n",
        "###- Generating insights through data\n",
        "###- Modelling of data"
      ],
      "metadata": {
        "id": "YvXMunt3kEsc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Iris plants Dataset\n",
        "##What does the dataset contain\n",
        "###- Classification of 150 plants based on petal and sepal sizes\n",
        "###- Small toy dataset perfectly suited for a data science introduction\n",
        "##What is the goal of the analysis\n",
        "###- Getting a feel for the data\n",
        "###- Trying out simple data science techniques\n",
        "###- Small glimpse into advanced machine learning techniques"
      ],
      "metadata": {
        "id": "dEoALI-bjgEZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlksoVwVeC3i"
      },
      "outputs": [],
      "source": [
        "!pip install numpy pandas matplotlib seaborn scikit-learn\n",
        "#!pip install torch torchvision torchaudio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext google.colab.data_table\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "qLuuI6vCjVh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "hW9oxOGDjcKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_iris()\n",
        "dataset"
      ],
      "metadata": {
        "id": "gX0Fgwcjkwj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset.keys())\n",
        "print(len(dataset.target))\n",
        "print(dataset.DESCR)"
      ],
      "metadata": {
        "id": "cPvIqYrdlFjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_dataframe = pd.DataFrame(\n",
        "    data=dataset.data,\n",
        "    columns=[\"sepal length [cm]\", \"sepal width [cm]\", \"petal length [cm]\", \"petal width [cm]\"]\n",
        ")\n",
        "iris_dataframe[\"species id\"] = dataset.target\n",
        "iris_dataframe[\"species\"] = pd.Series(dataset.target).apply(lambda x: dataset.target_names[x])\n",
        "iris_dataframe"
      ],
      "metadata": {
        "id": "hTvAg_2llQE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_dataframe.describe()"
      ],
      "metadata": {
        "id": "i3CVKckVmOvz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_dataframe.boxplot(column=list(iris_dataframe.columns)[:4], figsize=(17,14))"
      ],
      "metadata": {
        "id": "ydgGFfyRqdMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iris_dataframe.boxplot(column=list(iris_dataframe.columns)[:4], by=\"species\", figsize=(17,14))"
      ],
      "metadata": {
        "id": "ZUW-H-O1mZCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.boxplot(x=\"species\", y=\"petal length [cm]\", data=iris_dataframe)"
      ],
      "metadata": {
        "id": "oStYXYTJtPix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Interlude:\n",
        "Analysis with and without known type (and in general with partial type or uncertain type, e.g. BKS with wrong types)"
      ],
      "metadata": {
        "id": "-BS4ENioq0mR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sns.FacetGrid(iris_dataframe, hue=\"species\", height=6).map(plt.scatter, \"sepal length [cm]\", \"sepal width [cm]\").add_legend()"
      ],
      "metadata": {
        "id": "11FGnbjipEVL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.pairplot(iris_dataframe.drop(\"species id\", axis=1), hue=\"species\", height=3)"
      ],
      "metadata": {
        "id": "2vYDV2kAsGdv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sklearn functions for this exist but we do it manually with dfs to emulate real world\n",
        "x = iris_dataframe.iloc[:,0:4].to_numpy()\n",
        "y = iris_dataframe[\"species id\"].to_numpy()\n",
        "\n",
        "#logreg = LogisticRegression(random_state=0).fit(iris_dataframe.iloc[:,0:4], iris_dataframe[\"species id\"])\n",
        "logreg = LogisticRegression(random_state=0, max_iter=1000).fit(x, y)\n",
        "prediction = logreg.predict(x)\n",
        "print(prediction)\n",
        "print((iris_dataframe[\"species id\"] != prediction).sum())\n",
        "print(f\"{np.around(100*(1.0 - 4.0/150),1)}%\")"
      ],
      "metadata": {
        "id": "ydIaTz4buUdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sepal_width = 3\n",
        "sepal_length = 5.6\n",
        "x_min, x_max = x[:, 2].min() - 0.5, x[:, 2].max() + 0.5\n",
        "y_min, y_max = x[:, 3].min() - 0.5, x[:, 3].max() + 0.5\n",
        "h = 0.02 \n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "sample_size = xx.ravel().shape[0]\n",
        "synthetic_data = np.hstack((sepal_length*np.ones((sample_size,1)), sepal_width*np.ones((sample_size,1)), xx.reshape((-1,1)), yy.reshape((-1,1))))\n",
        "Z = logreg.predict(synthetic_data)\n",
        "\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1, figsize=(10, 8))\n",
        "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "\n",
        "plt.scatter(x[:, 2], x[:, 3], c=y, edgecolors=\"k\", cmap=plt.cm.Paired, s=70)\n",
        "plt.xlabel(\"Petal length [cm]\")\n",
        "plt.ylabel(\"Petal width [cm]\")\n",
        "\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8trZxTxF2LqA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tsne = TSNE(n_components=2, n_iter=1000, random_state=0)\n",
        "tsne_fit = tsne.fit_transform(iris_dataframe.iloc[:, 0:4].to_numpy())\n",
        "plt.figure(1, figsize=(10,8))\n",
        "plt.scatter(tsne_fit[:, 0], tsne_fit[:, 1], c=y, edgecolors=\"k\", s=70)\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")"
      ],
      "metadata": {
        "id": "R-70Ey-d8Vvd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(n_components=2)\n",
        "pca_fit = pca.fit_transform(iris_dataframe.iloc[:,0:4])\n",
        "plt.figure(1, figsize=(10,8))\n",
        "plt.scatter(pca_fit[:, 0], pca_fit[:, 1], c=y, edgecolors=\"k\", s=70)\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")"
      ],
      "metadata": {
        "id": "nCqCRDcd8_iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_min, x_max = pca_fit[:, 0].min() - 0.5, pca_fit[:, 0].max() + 0.5\n",
        "y_min, y_max = pca_fit[:, 1].min() - 0.5, pca_fit[:, 1].max() + 0.5\n",
        "h = 0.02 \n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "sample_size = xx.ravel().shape[0]\n",
        "synthetic_data = np.hstack((xx.reshape((-1,1)), yy.reshape((-1,1))))\n",
        "logreg = LogisticRegression(random_state=0, max_iter=1000).fit(pca_fit, y)\n",
        "Z = logreg.predict(synthetic_data)\n",
        "#Worse result?\n",
        "print(f\"{np.around(100*(1.0-(logreg.predict(pca_fit) != y).sum()/150.0), 1)}%\")\n",
        "\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1, figsize=(10, 8))\n",
        "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "\n",
        "plt.scatter(pca_fit[:, 0], pca_fit[:, 1], c=y, edgecolors=\"k\", cmap=plt.cm.Paired, s=70)\n",
        "plt.xlabel(\"Petal length [cm]\")\n",
        "plt.ylabel(\"Petal width [cm]\")\n",
        "\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5s_72KDb-0gD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sepal_width = 3\n",
        "sepal_length = 5.6\n",
        "x_min, x_max = x[:, 2].min() - 0.5, x[:, 2].max() + 0.5\n",
        "y_min, y_max = x[:, 3].min() - 0.5, x[:, 3].max() + 0.5\n",
        "h = 0.02 \n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "sample_size = xx.ravel().shape[0]\n",
        "synthetic_data = np.hstack((sepal_length*np.ones((sample_size,1)), sepal_width*np.ones((sample_size,1)), xx.reshape((-1,1)), yy.reshape((-1,1))))\n",
        "#Performance vs overfit\n",
        "#rfclass = RandomForestClassifier(max_depth=2, random_state=0).fit(x, y)\n",
        "rfclass = RandomForestClassifier(random_state=0).fit(x, y)\n",
        "Z = rfclass.predict(synthetic_data)\n",
        "print(f\"{np.around(100*(1.0-(rfclass.predict(x) != y).sum()/150.0), 1)}%\")\n",
        "\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1, figsize=(10, 8))\n",
        "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "\n",
        "plt.scatter(x[:, 2], x[:, 3], c=y, edgecolors=\"k\", cmap=plt.cm.Paired, s=70)\n",
        "plt.xlabel(\"Petal length [cm]\")\n",
        "plt.ylabel(\"Petal width [cm]\")\n",
        "\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "#why is the 1 brown point in wrong region?\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZVWiZDrBBrw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_hidden_layers):\n",
        "    super(MLP, self).__init__()\n",
        "    self.num_hidden_layers = num_hidden_layers if num_hidden_layers > 2 else 2\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size  = hidden_size\n",
        "    self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "    self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.out = torch.nn.Linear(self.hidden_size, 3)\n",
        "    self.sigmoid = torch.nn.Sigmoid()\n",
        "  def forward(self, x):\n",
        "    hidden = self.relu(self.fc1(x))\n",
        "    for i in range(self.num_hidden_layers - 2):\n",
        "      hidden = self.relu(self.fc2(hidden))\n",
        "    output = self.out(hidden)\n",
        "    output = self.sigmoid(output)\n",
        "    return output\n",
        "\n",
        "def train_model(model, optimizer, epochs, x, y, criterion):\n",
        "  x_train = torch.tensor(x).to(torch.float)\n",
        "  y_train = torch.tensor(y).to(torch.float)\n",
        "  model.train()\n",
        "  for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred, y_train)\n",
        "    \n",
        "    if epoch % (epochs//20) == 0:\n",
        "      print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "VZOaa9gEF__M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sepal_width = 3\n",
        "sepal_length = 5.6\n",
        "x_min, x_max = x[:, 2].min() - 0.5, x[:, 2].max() + 0.5\n",
        "y_min, y_max = x[:, 3].min() - 0.5, x[:, 3].max() + 0.5\n",
        "h = 0.02 \n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "sample_size = xx.ravel().shape[0]\n",
        "synthetic_data = np.hstack((sepal_length*np.ones((sample_size,1)), sepal_width*np.ones((sample_size,1)), xx.reshape((-1,1)), yy.reshape((-1,1))))\n",
        "\n",
        "model = MLP(4, 50, 7)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(y.reshape((-1,1)))\n",
        "y_oh = enc.transform(y.reshape((-1,1))).toarray()\n",
        "train_model(model, optimizer, 10000, x, y_oh, torch.nn.BCELoss())\n",
        "\n",
        "Z_oh = model(torch.Tensor(synthetic_data).to(torch.float))\n",
        "Z = enc.inverse_transform(Z_oh.detach())\n",
        "x_pred_oh = model(torch.Tensor(x).to(torch.float))\n",
        "x_pred = enc.inverse_transform(x_pred_oh.detach())\n",
        "print(f\"{np.around(100*(1.0-(x_pred.ravel() != y).sum()/150.0), 1)}%\")\n",
        "\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1, figsize=(10, 8))\n",
        "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "\n",
        "plt.scatter(x[:, 2], x[:, 3], c=y, edgecolors=\"k\", cmap=plt.cm.Paired, s=70)\n",
        "plt.xlabel(\"Petal length [cm]\")\n",
        "plt.ylabel(\"Petal width [cm]\")\n",
        "\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y-ZzycLgEE6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_min, x_max = pca_fit[:, 0].min() - 0.5, pca_fit[:, 0].max() + 0.5\n",
        "y_min, y_max = pca_fit[:, 1].min() - 0.5, pca_fit[:, 1].max() + 0.5\n",
        "h = 0.02 \n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "sample_size = xx.ravel().shape[0]\n",
        "synthetic_data = np.hstack((xx.reshape((-1,1)), yy.reshape((-1,1))))\n",
        "\n",
        "model = MLP(2, 50, 7)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "\n",
        "enc = OneHotEncoder(handle_unknown='ignore')\n",
        "enc.fit(y.reshape((-1,1)))\n",
        "y_oh = enc.transform(y.reshape((-1,1))).toarray()\n",
        "#print(y_oh)\n",
        "train_model(model, optimizer, 10000, pca_fit, y_oh, torch.nn.BCELoss())\n",
        "\n",
        "Z_oh = model(torch.Tensor(synthetic_data).to(torch.float))\n",
        "#print(Z_oh)\n",
        "Z = enc.inverse_transform(Z_oh.detach())\n",
        "x_pred_oh = model(torch.Tensor(pca_fit).to(torch.float))\n",
        "x_pred = enc.inverse_transform(x_pred_oh.detach())\n",
        "#print(x_pred)\n",
        "print(f\"{np.around(100*(1.0-(x_pred.ravel() != y).sum()/150.0), 1)}%\")\n",
        "\n",
        "Z = Z.reshape(xx.shape)\n",
        "plt.figure(1, figsize=(10, 8))\n",
        "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
        "\n",
        "plt.scatter(pca_fit[:, 0], pca_fit[:, 1], c=y, edgecolors=\"k\", cmap=plt.cm.Paired, s=70)\n",
        "plt.xlabel(\"Petal length [cm]\")\n",
        "plt.ylabel(\"Petal width [cm]\")\n",
        "\n",
        "plt.xlim(xx.min(), xx.max())\n",
        "plt.ylim(yy.min(), yy.max())\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "#why is the 1 brown point in wrong region?\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "iX5gk1oPJH7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AutoEncoder(torch.nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, latent_size, num_hidden_layers_each):\n",
        "    super(AutoEncoder, self).__init__()\n",
        "    self.num_hidden_layers = num_hidden_layers_each if num_hidden_layers_each > 2 else 2\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.latent_size = latent_size\n",
        "    self.fc1 = torch.nn.Linear(self.input_size, self.hidden_size)\n",
        "    self.fc2 = torch.nn.Linear(self.hidden_size, self.hidden_size)\n",
        "    self.fc3 = torch.nn.Linear(self.hidden_size, self.latent_size)\n",
        "    self.fc4 = torch.nn.Linear(self.latent_size, self.hidden_size)\n",
        "    self.out = torch.nn.Linear(self.hidden_size, self.input_size)\n",
        "    self.relu = torch.nn.ReLU()\n",
        "    self.sigmoid = torch.nn.Sigmoid()\n",
        "  def forward(self, x):\n",
        "    hidden = self.relu(self.fc1(x))\n",
        "    for i in range(self.num_hidden_layers - 2):\n",
        "      hidden = self.relu(self.fc2(hidden))\n",
        "    latent = self.relu(self.fc3(hidden))\n",
        "    hidden = self.relu(self.fc4(latent))\n",
        "    for i in range(self.num_hidden_layers - 2):\n",
        "      hidden = self.relu(self.fc2(hidden))\n",
        "    output = self.out(hidden)\n",
        "    return latent, output\n",
        "\n",
        "def train_model(model, optimizer, epochs, x, y, criterion, verbose = False):\n",
        "  x_train = torch.tensor(x).to(torch.float)\n",
        "  y_train = torch.tensor(y).to(torch.float)\n",
        "  model.train()\n",
        "  for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred[1], y_train)\n",
        "    \n",
        "    if epoch % (epochs//20) == 0:\n",
        "      print('Epoch {}: train loss: {}'.format(epoch, loss.item()))\n",
        "      if verbose:\n",
        "        print(np.around(np.hstack((y_pred[1].detach()[[30,60,90,120],], y_train[[30,60,90,120]])),1))\n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "def train_model_triplet(model, optimizer, epochs, x, y, criterion, t_lambda = 0.001, r_lambda = 1, verbose = False):\n",
        "  x_train = torch.tensor(x).to(torch.float)\n",
        "  y_train = torch.tensor(y).to(torch.float)\n",
        "  model.train()\n",
        "  for epoch in range(epochs):\n",
        "    optimizer.zero_grad()\n",
        "    # Forward pass\n",
        "    y_pred = model(x_train)\n",
        "    # Compute Loss\n",
        "    loss = criterion(y_pred[1], y_train)\n",
        "\n",
        "    random_sequence = torch.randint(0, 50, size=(50,))\n",
        "\n",
        "    y_s0 = y_pred[0][random_sequence]\n",
        "    y_s1 = y_pred[0][50+random_sequence]\n",
        "    y_s2 = y_pred[0][100+random_sequence]\n",
        "    \n",
        "    t1_loss = -criterion(y_s1, y_s0)\n",
        "    t2_loss = -criterion(y_s2, y_s0)\n",
        "    t21_loss = -criterion(y_s2, y_s1)\n",
        "\n",
        "    #alternative would be l1/l2 regularization of weights!\n",
        "    r0_loss = criterion(y_s0, torch.normal(1, 2, y_s0.shape))\n",
        "    r1_loss = criterion(y_s1, torch.normal(1, 2, y_s0.shape))\n",
        "    r2_loss = criterion(y_s2, torch.normal(1, 2, y_s0.shape))\n",
        "\n",
        "    full_loss = loss + t_lambda * (t1_loss + t2_loss + t21_loss) + r_lambda * (r0_loss + r1_loss + r2_loss)\n",
        "    \n",
        "    if epoch % (epochs//20) == 0:\n",
        "      print('Epoch {}: l: {} t1l: {} t2l: {} t21l: {}'.format(epoch, loss.item(), t1_loss.item(), t2_loss.item(), t21_loss.item()))\n",
        "      if verbose:\n",
        "        print(np.around(np.hstack((y_pred[1].detach()[[30,60,90,120],], y_train[[30,60,90,120]], y_pred[0].detach()[[30,60,90,120]])),1))\n",
        "    # Backward pass\n",
        "    full_loss.backward()\n",
        "    optimizer.step()"
      ],
      "metadata": {
        "id": "m8c2M-CnQnq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoEncoder(4, 50, 2, 14)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0005)\n",
        "train_model(model, optimizer, 12500, x, x, torch.nn.MSELoss(), verbose=True)\n",
        "\n",
        "latent, x_recon = model(torch.Tensor(x).to(torch.float))\n",
        "latent, x_recon = latent.detach(), x_recon.detach()\n",
        "\n",
        "plt.figure(1, figsize=(10, 8))\n",
        "\n",
        "plt.scatter(latent[:, 0], latent[:, 1], c=y, edgecolors=\"k\", cmap=plt.cm.Paired, s=70)\n",
        "plt.xlabel(\"Latent variable 1\")\n",
        "plt.ylabel(\"Latent variable 2\")\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MJL1aJaHUMuK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoEncoder(4, 50, 2, 7)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001, weight_decay=0.01)\n",
        "train_model_triplet(model, optimizer, 10000, x, x, torch.nn.MSELoss(), verbose=True)\n",
        "\n",
        "latent, x_recon = model(torch.Tensor(x).to(torch.float))\n",
        "latent, x_recon = latent.detach(), x_recon.detach()\n",
        "\n",
        "plt.figure(1, figsize=(10, 8))\n",
        "\n",
        "plt.scatter(latent[:, 0], latent[:, 1], c=y, edgecolors=\"k\", cmap=plt.cm.Paired, s=70)\n",
        "plt.xlabel(\"Latent variable 1\")\n",
        "plt.ylabel(\"Latent variable 2\")\n",
        "\n",
        "plt.xticks(())\n",
        "plt.yticks(())\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IERWi2I9U0EQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}